---
title: "Device Identification Based on Radio Signals Using Deep Metric Learning"
date: 2025-09-02-rff 10:00:00 +0000
categories: [Machine Learning, Deep Learning, Radio Frequency Fingerprinting]
tags: [Radio Frequency Fingerprinting, Signal Processing, RiftNet, OpenSet Problem, Metric Learning]
author: adinh26101
icon: fas fa-chart-bar
lang: en
math: true
permalink: /posts/rff-based-device-identify/
---

### Contents
- [1. Introduction](#-introduction)
- [2. Related Work](#-related-work)
- [3. Method](#-method)
- [4. Experiment](#-experiment)
- [5. Result](#-result)


<a name="-introduction"></a>  
## 1. Introduction

**Radio Frequency Fingerprinting (RFF)** is a technique for identifying radio devices based on unique characteristics (*fingerprints*) generated by **hardware imperfections** during RF signal transmission.

<p>
    <img src="assets/2025-09-02-rff/signal_component.png" alt="ThaÃÄnh ph√¢ÃÄn c∆° baÃân cuÃâa tiÃÅn hi√™Ã£u"/>
</p>

- Each device (WiFi, IoT, phones, drones, etc.) inherently has **small unavoidable errors** in circuits (*oscillator, PA, DAC...*) when transmitting.  
- These imperfections create a **distinct electromagnetic ‚Äúfingerprint.‚Äù**  
- By **extracting these features** from received signals (e.g., *IQ imbalance, phase noise, transient, spectral features*‚Ä¶), devices can be identified and distinguished even when using **the same communication standard and MAC/IP address.**  

### Main applications of RFF
- **Wireless network security**: detect impersonation, prevent spoofing.  
- **IoT**: lightweight device identification and authentication without heavy protocols.  
- **Military & Drones**: distinguish unmanned aerial vehicles.  

<a name="-related-work"></a>  
## 2. Related Work

### Transient Signal Identification
Studies show that the *transient* stage in radio signals (between noise and steady state) contains key features for device identification. Precisely detecting the *transient* boundary is crucial to avoid errors affecting feature extraction and training.  

Common detection methods:
- **Bayesian change point detection**: based on *fractal dimension* changes.  
- **Phase-Based detection**: based on linear phase variations during the *transient* stage.  

### Machine Learning and Deep Learning Applications
Once the *transient* signal is extracted, supervised machine learning models like **SVM** perform well but heavily rely on accurate transient segmentation.  

To overcome this, **deep learning (CNN, LSTM)** leverages the full signal, reducing dependence on transient detection and improving accuracy. Recent models such as **RiftNet** have been applied to identify devices from smartphone Bluetooth signals.  

<a name="-method"></a>  
## 3. Method

### Signal Classification with Machine Learning

#### Instantaneous Phase Features
- Based on *transient-based RF fingerprinting*.  
- Extract high-order statistical features: **skewness, kurtosis, variance** from:
  - Instantaneous amplitude  
  - Instantaneous frequency  
  - Instantaneous phase  
- These features reflect micro hardware imperfections, creating a unique ‚Äúfingerprint‚Äù for each device.

#### TFED Features
- Use **Hilbert-Huang transform** to analyze signals in the time-frequency domain.  
- Extract feature groups:  
  - **Transient Signal** (e.g., duration, energy, phase entropy)  
  - **Envelope** (e.g., energy, envelope variance)  
  - **TFED-Time** (e.g., slope, variance, energy peak distribution)  
  - **TFED-Frequency** (e.g., peaks, energy variance)  
- Limitation: requires **manual extraction**, depends on accurate transient detection, and can lose information at low sampling rates.

### Signal Classification with RiftNet

<p>
    <img src="assets/2025-09-02-rff/riftnet_architecture.png" alt="Ki√™ÃÅn truÃÅc m√¥ hiÃÄnh RiftNet"/>
    <em>RiftNet architecture</em>
</p>

- RiftNet has **two branches**:  
  - Branch (A): processes long segments (~16 Œºs).  
  - Branch (B): processes short segments (~2.5 Œºs).  
- Both use **Dilated Convolutional Cells (DCC)** with different dilation rates to extract multi-scale temporal information.  
- Intermediate outputs are combined with **skip connections** and fed into the classification layer.  
- Advantage: effectively captures RF features, reduces reliance on manual feature extraction.

### Metric Learning and Open Set Problem

- After training **RiftNet**, the softmax layer is removed.  
- Apply **metric learning** with **contrastive loss**, train for **20 additional epochs**.  
- Extract latent vectors of known users and index them using **FAISS** for querying and evaluation.  
- A threshold of **1.0 (Euclidean distance)** in the embedding space separates **known** from **unknown users**.  

<a name="-experiment"></a>  
## 4. Experiment

### Dataset
- Public dataset from Uzundurukan et al. (2020), published in *Data, MDPI*, titled ‚ÄúA Database for the Radio Frequency Fingerprinting of Bluetooth Devices.‚Äù
- Paper link: https://www.mdpi.com/2306-5729/5/2/55
- Dataset link: https://doi.org/10.5281/zenodo.3876140
- **Bluetooth (BT)** signals, sampling rate **250 Msps**.  
- **13 devices** from **5 brands**, ~1950 recordings from 33 phones.  
- Data split: **80% train ‚Äì 20% test**.  

**Device list:** iPhone 4s, 5, 5s, 6, 6s, 7, 7 Plus, LG G4, Samsung Note 2, Note 3, S3, J7, Xiaomi Mi 6.  

### Machine Learning Classification
- Models: **SVM, LDA, Decision Tree, Random Forest, XGBoost, CatBoost, Gradient Boosting**.  
- Libraries: `scikit-learn`, `XGBoost`, `CatBoost`.  
- Default hyperparameters.  
- Training and evaluation on the same dataset.  

### RiftNet Classification
- Trained for **100 epochs**.  
- Optimizer: **Adam**, learning rate = `1e-4`.  
- Loss function: **cross-entropy**.  

<a name="-result"></a>  
## 5. Result

### Machine Learning Classification
- **Instantaneous features**:  
  - SVM: **67.42% (train)**, **42.22% (test)** ‚Üí low effectiveness.  

- **TFED features**:  
  - LDA: 73.64% (train) / 72.93% (test)  
  - Decision Tree: 100% / 56.57%  
  - Random Forest: 100% / 69.19%  
  - XGBoost: 100% / 70.61%  
  - CatBoost: 99.12% / 72.12%  
  - Gradient Boosting: 99.55% / 65.35%  

üëâ Results show **overfitting**: high training accuracy but large drop on test data. Main reason: **difficulty in accurately detecting transient stage**, making manual features (instantaneous, TFED) insufficient.  

### RiftNet Classification

<p>
    <img src="assets/2025-09-02-rff/riftnet_loss.png" alt="ƒê√¥ÃÄ thiÃ£ haÃÄm loss trong quaÃÅ triÃÄnh training"/>
    <em>Training loss curve</em>
</p>

<p>
    <img src="assets/2025-09-02-rff/riftnet_train_acc.png" alt="ƒê√¥ÃÄ thiÃ£ accuracy tr√™n t√¢Ã£p train"/>
    <em>Train accuracy curve</em>
</p>

<p>
    <img src="assets/2025-09-02-rff/riftnet_test_acc.png" alt="ƒê√¥ÃÄ thiÃ£ accuracy tr√™n t√¢Ã£p test"/>
    <em>Test accuracy curve</em>
</p>

<p>
    <img src="assets/2025-09-02-rff/riftnet_confusion_test.png" alt="Confusion matrix tr√™n t√¢Ã£p test"/>
    <em>Test confusion matrix</em>
</p>

- Model **converges quickly and stably**: loss drops sharply in early epochs.  
- Performance improves steadily on both train and test.  
- **Best result at epoch 96**:  
  - Train accuracy: **99.4%**  
  - Test accuracy: **96.57%**  
- Slight test fluctuations due to **small and limited diversity** in test data, causing potential *distribution shift*.  

üëâ **RiftNet outperforms** traditional machine learning models, demonstrating deep learning‚Äôs power in RFF identification.

### Metric Learning in Open Set

<p>
    <img src="assets/2025-09-02-rff/scatter_plot.png" alt="t-SNE plot"/>
    <em>Latent vectors clustered using t-SNE plot</em>
</p>

- After **metric learning**, the latent space forms **clear clusters** corresponding to known users.  
  - Devices of the same class group tightly.  
  - Different classes are well separated.  
  - Previously unseen devices appear as **outliers**, easily identifiable.  

<p>
    <img src="assets/2025-09-02-rff/openset_confusion.png" alt="openset problem tr√™n t√¢Ã£p test (coÃÅ unknown user)"/>
    <em>Open-set problem on test set (with unknown users)</em>
</p>

- Tested on **mixed dataset** (known + unknown devices):  
  - **Confusion matrix** shows accurate and stable predictions for known classes.  
  - Some misclassifications mainly occur with **unknown class**, normal for open-set.  
  - With **1.0 threshold (Euclidean distance)**, system achieves **97.05% accuracy** in separating known/unknown.  

üëâ Results prove RiftNet with metric learning has **high generalization** and strong potential for **device authentication using RF signals in open-set scenarios**.

Paper published in APSIPA ASC 2025, [check here]().  

Code used in the study is available in this repository, [check here](https://github.com/frogdance/rff-based-deep-metric-learning).
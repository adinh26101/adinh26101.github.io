---
title: "Federated Split Learning with Efficient File-Based Gradient Synchronization"
date: 2025-02-12 10:00:00 +0000
categories: [Deep Learning, Split Federated Learning, Docker, Microservice]
tags: [Deep Learning, Split Federated Learning, Docker, Microservice, Split Learning, GPU Container, File-Based Gradient, Synchronous]
author: adinh26101
icon: fas fa-ruler
lang: vi
permalink: /posts/micro-sfl/
math: true
pin: true
---

> Bài viết này giới thiệu tổng quan bối cảnh và ý tưởng chính của nghiên cứu. Các phân tích và thực nghiệm chi tiết được trình bày trong tài liệu tham khảo bên dưới.

Split Federated Learning (SFL) là một framework kết hợp giữa Split Learning và Federated Learning, được đề xuất bởi C. Thapa và cộng sự, với mục tiêu chính là giảm khối lượng tính toán phía client. Tuy nhiên, việc triển khai SFL trong thực tế vẫn còn nhiều thách thức.

![Kiến trúc SFL](assets/2025-12-02-micro-sfl/sfl.jpg)
*Kiến trúc SFL*

Trong kiến trúc SFL truyền thống, Split Server nắm giữ server-side model và lưu các gradient trung gian trong RAM, do đó phải duy trì trạng thái huấn luyện để cập nhật trọng số. Điều này khiến Split Server trở thành một stateful service, gây khó khăn khi triển khai trên môi trường cloud theo kiến trúc microservice, vốn ưu tiên các service stateless để dễ mở rộng và scale.

Trong nghiên cứu này, chúng tôi phân tích gradient flow của SFL và nhận thấy có thể sử dụng trung bình gradient theo batch để cập nhật trọng số. Cụ thể, activation và gradient được lưu trữ dưới dạng file, phục vụ cho quá trình forward và backward. Với cơ chế này, forward và backward có thể được xử lý song song, các gradient mới sẽ được lưu lại và chờ cập nhật, thay vì phải đồng bộ theo từng batch.

Cách tiếp cận này cho phép truyền gradient thông qua các API đơn giản. Trong bối cảnh Federated Learning với nhiều client tham gia đồng thời, việc này giúp giảm hiện tượng bottleneck và thời gian chờ đồng bộ, vốn thường phát sinh khi server phải đợi gradient từ tất cả client.

Khi Split Server chỉ đảm nhiệm việc tính toán forward activation và backward gradient, service này có thể được thiết kế như một stateless application, giúp việc scale hệ thống trở nên linh hoạt và hiệu quả hơn.

Trong phạm vi nghiên cứu hiện tại, chúng tôi tập trung chứng minh tính hiệu quả của phương pháp đồng bộ gradient dựa trên file và API. Trong các kịch bản mở rộng, gradient có thể được lưu trên persistent storage, sau mỗi vòng huấn luyện sẽ được trung bình hóa để cập nhật server-side model, sau đó phân phối lại cho tất cả các instance của Split Server. Cách tiếp cận này phù hợp với các hệ thống cloud-native và microservice-oriented.

![Scale](assets/2025-12-02-micro-sfl/scale.jpg)
*Minh họa cơ chế mở rộng của hệ thống SFL khi Split Server được thiết kế theo hướng stateless, cho phép triển khai linh hoạt và mở rộng ngang trong môi trường microservice.*

Phân tích chi tiết về gradient flow, kiến trúc hệ thống và kết quả thực nghiệm được trình bày tại:  
[tại đây](https://doi.org/10.22967/HCIS.2026.16.013)

Mã nguồn sử dụng cho thực nghiệm:  
[tại đây](https://github.com/frogdance/MicroSFL)
